{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "def textTransformation(sents):\n",
    "    rs_sents = []\n",
    "    for example_sent in sents:\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        word_tokens = word_tokenize(example_sent) #tokenization\n",
    "        filtered_sentence = []\n",
    "\n",
    "        for w in word_tokens: #removal stopwords\n",
    "            if w not in stop_words:\n",
    "                filtered_sentence.append(w)\n",
    "\n",
    "#         print(filtered_sentence)\n",
    "\n",
    "        from nltk.stem import PorterStemmer\n",
    "\n",
    "        ps = PorterStemmer()\n",
    "        sent = \"\"\n",
    "        for w in filtered_sentence: #stemming\n",
    "            sent += ps.stem(w) + \" \"\n",
    "        rs_sents.append(sent.strip())\n",
    "\n",
    "    return rs_sents\n",
    "\n",
    "example_sents = [\n",
    "    \"breakthrough drug for schizophrenia\", #doc0\n",
    "    \"new schizophrenia drug\", #doc1\n",
    "    \"new approach for treatment of schizophrenia\", #doc2\n",
    "    \"new hopes for schizophrenia patients\" #doc3\n",
    "]\n",
    "\n",
    "example_sents =  textTransformation(example_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "query 1\n",
      "[[0.68701684]]\n",
      "[[0.8288098]]\n",
      "[[0.1759481]]\n",
      "[[0.1759481]]\n",
      "\n",
      "query 2\n",
      "[[0.17542822]]\n",
      "[[0.21163474]]\n",
      "[[0.14748024]]\n",
      "[[0.68905279]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# create the transform (Note: that values are normalized from 0 to 1)\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(example_sents)\n",
    "\n",
    "# encode document\n",
    "vector = vectorizer.transform(example_sents)\n",
    "\n",
    "# summarize encoded vector\n",
    "# print(vector.toarray())\n",
    "print()\n",
    "querys = ['schizophrenia drug', 'schizophrenia patient']\n",
    "query_vector = vectorizer.transform(querys)\n",
    "# print(query_vector.toarray())\n",
    "# # creating separate vectors\n",
    "query_vector = [query_vector[0].toarray(), query_vector[1].toarray()]\n",
    "\n",
    "# # calculate cosine similarity\n",
    "for x in range(len(query_vector)):\n",
    "    print(\"query {}\".format(x+1))\n",
    "    for i in range(len(example_sents)):\n",
    "        print(cosine_similarity(query_vector[x], vector[i].toarray()))\n",
    "    print()\n",
    "\n",
    "# print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
